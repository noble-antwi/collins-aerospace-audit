# COBIT 2019 Framework Enhancement for AI Era

**Course:** ITMM 586 - Information Technology Auditing  
**Student:** Noble Antwi  
**Partner:** Krupa Prakash Panchal  
**Instructor:** Professor Ann Rangarajan  
**Institution:** Illinois Institute of Technology  
**Date:** September 17, 2025  
**Assignment:** Question 2 - Framework Enhancement (50 points)

---

## Assignment Overview

**Objective:** Propose enhancements to at least 10 COBIT 2019 objectives (2 per domain) to address next-generation technologies, particularly Generative AI, based on insights from KPMG's "Future of Audit" materials.

**Format:** 100-150 words per objective

**Research Foundation:**
- KPMG "Transforming Audit with AI" video and content
- COBIT 2019 Governance-Management-Objectives-Practices-Activities framework
- Current AI implementation trends in enterprise environments

---

## Executive Summary

After reviewing the KPMG video on transforming audit with AI and analyzing the COBIT 2019 framework objectives, I believe significant enhancements are needed to address the surge of next-generation technologies, particularly Generative AI. The current framework, while comprehensive, doesn't fully capture the governance and management challenges presented by AI-driven business environments.

---

## Domain 1: EDM (Evaluate, Direct and Monitor) - Governance Objectives

### EDM01 Enhanced - AI Ethics and Algorithmic Accountability Framework

**Current Objective:** Ensured Governance Framework Setting and Maintenance

**Proposed Enhancement:**

The current objective focuses on traditional governance frameworks but needs enhancement for AI governance. I propose expanding this to include "AI Ethics and Algorithmic Accountability Framework." Given the KPMG video's emphasis on responsible AI implementation and avoiding biases in decision-making processes, governance frameworks must now establish clear AI ethics policies, algorithmic transparency requirements, and accountability structures. This enhancement would ensure that AI systems align with organizational values and regulatory requirements while maintaining stakeholder trust. The framework should address AI model governance, bias detection protocols, and explainability requirements that weren't considered when COBIT 2019 was developed.

**Key Components:**
- AI ethics committee establishment and charter
- Algorithmic impact assessment processes
- Bias detection and mitigation protocols  
- Stakeholder accountability frameworks
- Regular ethical compliance auditing
- AI decision explainability standards

**Rationale:**
As AI systems make increasingly autonomous decisions affecting stakeholders, organizations need governance frameworks that address ethical implications, not just technical performance. The KPMG video emphasizes responsible AI implementation—this enhancement operationalizes that responsibility at the governance level.

---

### EDM06 New Objective - AI Risk and Opportunity Balance

**Why This New Objective Is Needed:**

While risk optimization exists in EDM03, AI introduces a unique risk-opportunity profile that requires specialized governance oversight. The video highlighted how AI creates both tremendous opportunities and new risk categories. This new objective would focus specifically on governing AI-related risks including algorithmic bias, model drift, adversarial attacks, and unintended consequences. It would also ensure that governance bodies understand AI's transformative potential while establishing appropriate risk appetites for AI initiatives. The objective would include oversight of continuous AI model monitoring and establishing risk thresholds for automated decision-making systems that could significantly impact business operations.

**Key Components:**
- AI risk appetite definition and communication
- AI opportunity assessment and prioritization frameworks
- Continuous AI model risk monitoring oversight
- Strategic AI investment decision governance
- AI-related crisis management planning and preparedness

**Rationale:**
Traditional risk management treats technology as a tool to be governed. AI, however, acts as an autonomous decision-maker, creating risks that are probabilistic, evolving, and potentially catastrophic. This requires dedicated governance attention at the EDM level.

---

## Domain 2: APO (Align, Plan and Organize) - Management Objectives

### APO04 Enhanced - AI-Driven Innovation Management

**Current Objective:** Managed Innovation

**Proposed Enhancement:**

The current innovation management objective needs significant enhancement for what I'd call "APO04+ - Managed AI-Driven Innovation." The KPMG video emphasizes AI as a driver of competitive advantage, but traditional innovation management doesn't address AI's unique characteristics. This enhanced objective would include AI capability assessment, AI talent acquisition and development strategies, and AI innovation pipeline management. It would ensure systematic evaluation of AI opportunities, proper resource allocation for AI initiatives, and establishment of AI centers of excellence. The enhancement recognizes that AI innovation requires different approaches than traditional IT innovation, including considerations for data quality, model lifecycle management, and interdisciplinary collaboration.

**Key Enhancements:**
- AI capability maturity assessment frameworks
- Specialized AI talent acquisition and retention strategies
- AI innovation pipeline with stage-gate processes tailored to AI development
- Cross-functional AI team organization (data scientists, ethicists, domain experts)
- AI center of excellence establishment and funding models

**Strategic Alignment:**
Ensures AI innovation initiatives align with enterprise strategy while addressing unique technical feasibility constraints, resource requirements, and competitive positioning in AI-enabled markets.

---

### APO15 New Objective - AI Model Risk Management

**Why This New Objective Is Needed:**

I propose expanding general risk management with "APO15 - Managed AI Model Risk." While general risk management exists (APO12), AI introduces specific risks that require specialized management approaches. This new objective would address AI model risk management including model validation, performance monitoring, and bias detection. As the video mentions, we must "look beyond the hype and act responsibly," which requires dedicated AI risk management processes. The objective would cover adversarial risks, model interpretability requirements, and automated risk detection systems that can identify anomalies in real-time—directly addressing the video's emphasis on continuous auditing capabilities.

**Core Activities:**
- AI model validation and testing protocols (pre-deployment)
- Continuous model performance monitoring systems
- Adversarial attack risk assessment and mitigation strategies
- Model drift detection and automated response procedures
- Automated anomaly detection and alerting systems
- Model retirement and replacement procedures

**Integration Points:**
This objective integrates with EDM06 (governance oversight) and DSS01+ (operational monitoring) to create end-to-end AI model risk management.

---

## Domain 3: BAI (Build, Acquire and Implement) - Management Objectives

### BAI03 Enhanced - AI Solution Development and Deployment

**Current Objective:** Managed Solutions Identification and Build

**Proposed Enhancement:**

Current solution development processes need enhancement for what I call "BAI03+ - Managed AI Solution Development and Deployment." Traditional solution development doesn't account for AI's iterative nature, data dependency, and continuous learning requirements. This enhanced objective would include AI model development lifecycle management, automated testing protocols, and responsible AI deployment practices. It would ensure proper AI model versioning, A/B testing frameworks, and gradual rollout strategies. The enhancement acknowledges that AI solutions require different development approaches, including considerations for training data governance, model bias testing, and performance drift monitoring.

**Key Modifications:**
- Agile AI development methodologies with continuous integration/continuous deployment
- AI model versioning and reproducibility management systems
- Comprehensive AI testing protocols including bias testing and edge case analysis
- Responsible AI deployment with gradual rollout strategies (canary deployments, blue-green)
- AI model performance validation gates before production deployment
- Rollback and model switching capabilities

**Development Lifecycle Differences:**
Unlike traditional software where bugs are deterministic, AI systems fail probabilistically. This enhancement addresses the unique challenge of validating systems that learn and adapt.

---

### BAI12 New Objective - AI Models and Data Assets Management

**Why This New Objective Is Needed:**

I suggest adding "BAI12 - Managed AI Models and Data Assets." The video emphasizes AI's data-intensive nature and the critical importance of data quality. This new objective would specifically address AI model asset management including model repositories, version control, and lifecycle management. It would also cover training data asset management, synthetic data governance, and AI model intellectual property protection. As organizations develop numerous AI models, proper asset management becomes crucial for maintaining model performance, ensuring compliance, and maximizing AI investment returns. This objective would establish standards for AI model documentation, metadata management, and model performance tracking.

**Management Scope:**
- Centralized AI model repositories with version control and lineage tracking
- Training data asset cataloging and governance (provenance, quality, bias assessment)
- AI model documentation standards (purpose, limitations, performance metrics)
- Synthetic data generation and management protocols
- AI intellectual property protection and licensing management
- Model deprecation and archival procedures

**Value Proposition:**
Without systematic asset management, organizations lose track of which models exist, their performance characteristics, and their suitability for reuse. This creates redundant development efforts and compliance risks.

---

## Domain 4: DSS (Deliver, Service and Support) - Management Objectives

### DSS01 Enhanced - AI-Augmented Operations Management

**Current Objective:** Managed Operations

**Proposed Enhancement:**

The current operations management needs expansion to "DSS01+ - Managed AI-Augmented Operations." The KPMG video highlights how AI transforms operational efficiency through automation and continuous monitoring. This enhanced objective would include AI-driven operational monitoring, automated incident response, and intelligent resource optimization. It would ensure proper integration of AI tools into operational processes while maintaining human oversight. The enhancement would address the video's emphasis on continuous auditing by establishing real-time monitoring capabilities that can detect operational anomalies and automatically trigger appropriate responses.

**Operational Improvements:**
- AI-driven operational monitoring and alerting with predictive capabilities
- Automated incident detection and initial response procedures
- Intelligent resource optimization and capacity planning
- Human-AI collaboration workflow design (ensuring appropriate human oversight)
- Real-time operational anomaly detection and automated response triggering

**Human-AI Balance:**
While AI can monitor 24/7 and detect patterns humans miss, the video emphasized that critical thinking and curiosity remain human domains. This enhancement ensures AI augments rather than replaces human operational expertise.

---

### DSS07 New Objective - AI Security and Adversarial Protection

**Why This New Objective Is Needed:**

I propose adding "DSS07 - Managed AI Security and Adversarial Protection." Traditional security services don't adequately address AI-specific security threats. This new objective would focus on protecting AI systems from adversarial attacks, ensuring model integrity, and maintaining AI system availability. The video mentions AI's powerful role in cybersecurity, but AI systems themselves need protection. This objective would establish AI security monitoring, adversarial attack detection, and AI model hardening practices. It would also address privacy-preserving AI techniques and secure AI model deployment practices that protect both the AI systems and the data they process.

**Protection Framework:**
- AI system vulnerability assessment and hardening procedures
- Adversarial attack detection and mitigation systems (defending against poisoning, evasion)
- AI model integrity verification and monitoring (detecting tampering)
- Privacy-preserving AI technique implementation (differential privacy, federated learning)
- Secure AI model deployment and access controls
- AI system availability protection (defending against denial-of-service attacks targeting AI)

**Emerging Threat Landscape:**
As AI systems control increasingly critical functions, they become attractive targets. Adversarial attacks can cause AI systems to misclassify inputs or leak training data, creating novel security challenges.

---

## Domain 5: MEA (Monitor, Evaluate and Assess) - Management Objectives

### MEA01 Enhanced - AI Performance and Ethical Conformance Monitoring

**Current Objective:** Managed Performance and Conformance Monitoring

**Proposed Enhancement:**

Current monitoring needs enhancement for "MEA01+ - Managed AI Performance and Ethical Conformance Monitoring." The video emphasizes the need for transparency and continuous monitoring in AI systems. This enhanced objective would include AI model performance monitoring, bias detection and mitigation, and ethical compliance assessment. It would establish automated monitoring systems that can detect model drift, performance degradation, and ethical violations in real-time. The enhancement recognizes that AI systems require continuous monitoring for both technical performance and ethical compliance, going beyond traditional system monitoring to include fairness, transparency, and accountability metrics.

**Enhanced Capabilities:**
- Real-time AI model performance tracking and alerting (accuracy, precision, recall)
- Continuous bias detection and fairness monitoring across demographic groups
- Ethical compliance assessment and reporting against established AI ethics frameworks
- Model drift detection and performance degradation alerting
- Stakeholder impact monitoring and assessment (tracking real-world consequences)

**Dual Monitoring Approach:**
Traditional monitoring focuses on technical metrics (uptime, response time). AI systems also require ethical monitoring—are decisions fair? Are outcomes equitable? This enhancement operationalizes ethical AI principles through measurable monitoring.

---

### MEA04 Enhanced - AI Audit and Assurance

**Current Objective:** Managed Assurance (new in COBIT 2019)

**Proposed Enhancement:**

Building on COBIT 2019's new assurance objective, I suggest expanding it to "MEA04+ - Managed AI Audit and Assurance." The video highlights how AI transforms audit practices, but AI systems themselves need specialized assurance approaches. This enhanced objective would establish AI audit methodologies, automated audit procedures, and AI system certification processes. It would ensure that AI systems are auditable, explainable, and compliant with regulatory requirements. The enhancement would include continuous assurance practices that leverage AI tools for audit efficiency while maintaining the human oversight that the video emphasizes as essential for critical thinking and curiosity in the audit process.

**Advanced Assurance Capabilities:**
- AI system auditability design and verification (ensuring AI decisions can be audited)
- Automated audit procedure development and execution (AI-powered audit tools)
- AI model explainability assessment and validation (testing interpretability)
- Continuous assurance through AI-powered audit monitoring tools
- AI system certification and compliance verification processes
- Audit trail completeness verification for AI decision-making

**Assurance Evolution:**
The video showed AI as an audit tool. This enhancement recognizes AI systems themselves are audit subjects requiring specialized audit methodologies that account for their probabilistic, adaptive nature.

---

## Implementation Roadmap

### Phase 1: Foundation (Months 1-6)
- Establish AI governance committee and ethics framework (EDM01 Enhanced)
- Develop AI risk management policies and procedures (EDM06 New)
- Create AI talent acquisition strategy (APO04 Enhanced)
- Implement basic AI model development standards (BAI03 Enhanced)

### Phase 2: Operations (Months 7-12)
- Deploy AI-augmented operational monitoring (DSS01 Enhanced)
- Establish AI model asset management systems (BAI12 New)
- Implement continuous AI performance monitoring (MEA01 Enhanced)
- Develop AI security and protection protocols (DSS07 New)

### Phase 3: Optimization (Months 13-18)
- Mature AI audit and assurance capabilities (MEA04 Enhanced)
- Optimize AI risk and opportunity balance (EDM06 New)
- Advance AI-driven innovation management (APO04 Enhanced)
- Implement comprehensive AI model risk management (APO15 New)

---

## Integration with Existing COBIT Framework

These enhancements don't replace existing COBIT objectives; they extend them:

**Governance Level (EDM):**
- EDM01 Enhanced ensures AI governance is part of overall governance framework
- EDM06 New provides AI-specific risk-opportunity oversight

**Management Level (APO, BAI, DSS, MEA):**
- Enhancements integrate with existing objectives (marked with "+")
- New objectives (numbered sequentially: APO15, BAI12, DSS07) fill AI-specific gaps
- All connect through COBIT's cascade model (governance → management → operations)

---

## Alignment with KPMG Video Themes

### Theme 1: Continuous Monitoring and Auditing
**Addressed by:** MEA01+ (AI Performance Monitoring), DSS01+ (AI-Augmented Operations), MEA04+ (AI Audit and Assurance)

### Theme 2: Responsible AI Implementation  
**Addressed by:** EDM01+ (AI Ethics Framework), EDM06 (AI Risk-Opportunity Balance), APO15 (AI Model Risk Management)

### Theme 3: Human-AI Collaboration
**Addressed by:** All enhancements emphasize appropriate human oversight while leveraging AI capabilities

### Theme 4: Data Quality and Governance
**Addressed by:** BAI12 (AI Models and Data Assets Management), APO04+ (AI Innovation includes data considerations)

---

## Conclusion

These enhancements and additions reflect the fundamental shift toward AI-driven business operations while maintaining COBIT's focus on governance, risk management, and value creation. They address the video's key themes of responsible innovation, continuous monitoring, and the critical balance between technological advancement and human oversight.

The proposed changes transform COBIT 2019 from a traditional IT governance framework into a comprehensive AI-ready governance system. Organizations implementing these enhancements will be better positioned to:
- Govern AI initiatives effectively
- Manage AI-related risks appropriately  
- Capitalize on AI's transformative potential
- Maintain ethical standards and regulatory compliance
- Balance innovation with responsibility

As the KPMG video emphasizes, AI is not just another technology—it's a fundamental transformation in how organizations operate, compete, and create value. COBIT must evolve accordingly to remain relevant in the AI era.

---

## References

### Primary Sources
- KPMG, "Transforming Audit with AI," Future of Audit video series
- ISACA, "COBIT 2019 Framework: Governance and Management Objectives," November 2018
- COBIT 2019 Governance-Management-Objectives-Practices-Activities Excel workbook

### Secondary Analysis  
- Industry AI governance best practices
- Regulatory developments in AI oversight (EU AI Act, NIST AI Risk Management Framework)
- Academic research on AI ethics and responsible AI deployment

---

**Document Version:** 1.0  
**Word Count:** ~2,400 words (10 objectives × ~150 words + framework content)  
**Last Updated:** September 17, 2025  
**Classification:** Academic Assignment - ITMM 586
